#!/usr/bin/env python
"""
æ•°æ®å‡†å¤‡è„šæœ¬
1. æ ¹æ® .env ä¸­çš„ DATASET_NAME ä¸‹è½½åŸå§‹æ•°æ®åˆ° data/raw/
2. æ¸…æ´—æ•°æ®å¹¶ä¿å­˜åˆ° data/processed/
3. ç”Ÿæˆ train_clean.csv å’Œ eval_clean.csv ä¾› run_evolution.py ä½¿ç”¨
"""
import os
import re
import random
from pathlib import Path
from typing import Optional, Dict, Tuple

import pandas as pd
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

BASE_DIR = Path(__file__).parent
DATASET_NAME = os.getenv("DATASET_NAME", "ielts_chillies")


# ==================== æ•°æ®ä¸‹è½½å‡½æ•° ==================== #

def download_ielts_chillies():
    """ä» Hugging Face ä¸‹è½½ IELTS Chillies æ•°æ®é›†"""
    from datasets import load_dataset
    
    print("ğŸ“¥ æ­£åœ¨ä» Hugging Face ä¸‹è½½ IELTS Chillies æ•°æ®é›†...")
    
    output_dir = BASE_DIR / "data" / "ielts_chillies" / "raw"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    dataset = load_dataset("chillies/IELTS-writing-task-2-evaluation")
    df = dataset["train"].to_pandas()
    
    output_path = output_dir / "train.csv"
    df.to_csv(output_path, index=False, encoding="utf-8")
    
    print(f"âœ… ä¸‹è½½å®Œæˆ: {output_path} ({len(df)} è¡Œ)")
    return output_path


def download_ielts_kaggle():
    """ä» Kaggle ä¸‹è½½ IELTS æ•°æ®é›†"""
    print("ğŸ“¥ æ­£åœ¨ä¸‹è½½ IELTS Kaggle æ•°æ®é›†...")
    
    output_dir = BASE_DIR / "data" / "ielts_kaggle" / "raw"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ—§æ•°æ®å¯ä»¥å¤åˆ¶
    legacy_file = BASE_DIR / "data_legacy" / "raw" / "kaggle" / "ielts_writing_dataset.csv"
    output_file = output_dir / "ielts_writing_dataset.csv"
    
    if legacy_file.exists():
        import shutil
        print(f"   ä»æ—§æ•°æ®ç›®å½•å¤åˆ¶: {legacy_file}")
        shutil.copy(legacy_file, output_file)
        print(f"âœ… å¤åˆ¶å®Œæˆ: {output_file}")
        return output_file
    
    # å¦‚æœæ²¡æœ‰æ—§æ•°æ®ï¼Œå°è¯•ä» Kaggle ä¸‹è½½
    try:
        import kaggle
        print("âš ï¸  Kaggle IELTS æ•°æ®é›†éœ€è¦æ‰‹åŠ¨ä¸‹è½½")
        print("   è¯·è®¿é—® Kaggle æœç´¢ 'IELTS writing dataset' å¹¶ä¸‹è½½")
        print(f"   ç„¶åå°†æ–‡ä»¶æ”¾åˆ°: {output_file}")
        return None
    except ImportError:
        print("âŒ æœªå®‰è£… kaggle åŒ…ï¼Œè¯·è¿è¡Œ: pip install kaggle")
        return None


def download_asap():
    """ä» Kaggle ä¸‹è½½ ASAP æ•°æ®é›†"""
    print("ğŸ“¥ æ­£åœ¨ä¸‹è½½ ASAP æ•°æ®é›†...")
    
    output_dir = BASE_DIR / "data" / "asap" / "raw"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®æ–‡ä»¶
    output_path = output_dir / "training_set_rel3.tsv"
    if output_path.exists():
        print(f"âœ… æ•°æ®æ–‡ä»¶å·²å­˜åœ¨: {output_path}")
        return output_path
    
    try:
        import kaggle
        import zipfile
        
        print("   å°è¯•ä» Kaggle API ä¸‹è½½...")
        kaggle.api.competition_download_files('asap-aes', path=output_dir, quiet=False)
        
        zip_path = output_dir / "asap-aes.zip"
        if zip_path.exists():
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(output_dir)
            zip_path.unlink()
            
            if output_path.exists():
                print(f"âœ… ä¸‹è½½å®Œæˆ: {output_path}")
                return output_path
    except ImportError:
        print("âŒ æœªå®‰è£… kaggle åŒ…ï¼Œè¯·è¿è¡Œ: pip install kaggle")
    except Exception as e:
        print(f"âŒ API ä¸‹è½½å¤±è´¥: {e}")
    
    # æä¾›æ‰‹åŠ¨ä¸‹è½½æŒ‡å¼•
    print("\n" + "="*60)
    print("âš ï¸  ASAP æ•°æ®é›†éœ€è¦æ‰‹åŠ¨ä¸‹è½½")
    print("="*60)
    print("\nè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š")
    print("\n1. è®¿é—® ASAP-AES ç«èµ›é¡µé¢:")
    print("   https://www.kaggle.com/c/asap-aes")
    print("\n2. ç‚¹å‡» 'Join Competition' å¹¶æ¥å—è§„åˆ™")
    print("\n3. è¿›å…¥ Data æ ‡ç­¾é¡µ:")
    print("   https://www.kaggle.com/c/asap-aes/data")
    print("\n4. ä¸‹è½½ 'training_set_rel3.tsv' æ–‡ä»¶")
    print(f"\n5. å°†æ–‡ä»¶æ”¾åˆ°ä»¥ä¸‹ç›®å½•:")
    print(f"   {output_dir}/")
    print("\n6. é‡æ–°è¿è¡Œ: uv run prepare_data.py")
    print("="*60)
    
    return None


# ==================== æ•°æ®æ¸…æ´—å‡½æ•° ==================== #

def safe_parse_band(val) -> Optional[float]:
    """
    è§£æ band åˆ†æ•°ï¼Œæ”¯æŒå¤šç§æ ¼å¼:
    - "7.5", "5.0\\n\\n"
    - "<4", "<4\\n\\n"
    - "Band: 6.5"
    """
    if val is None:
        return None
    s = str(val).strip()
    if not s:
        return None
    
    nums = re.findall(r"\d+(?:\.\d+)?", s)
    if not nums:
        return None
    
    band = float(nums[0])
    if s.lstrip().startswith("<"):
        band -= 0.5
    
    # é™åˆ¶åœ¨ 0-9 èŒƒå›´ï¼Œå››èˆäº”å…¥åˆ° 0.5
    band = max(0.0, min(9.0, band))
    band = round(band * 2) / 2.0
    return band


def clean_ielts_chillies_data(df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, int]]:
    """æ¸…æ´— IELTS Chillies æ•°æ®é›†ï¼ˆHuggingFaceï¼‰"""
    stats = {
        "raw_rows": len(df),
        "drop_na": 0,
        "bad_band": 0,
        "bad_len": 0,
        "dedup": 0,
    }
    
    # åˆ é™¤ç¼ºå¤±å€¼
    df = df.dropna(subset=["prompt", "essay", "band"]).reset_index(drop=True)
    stats["drop_na"] = stats["raw_rows"] - len(df)
    
    # è§£æ band åˆ†æ•°
    df["band_clean"] = df["band"].apply(safe_parse_band)
    bad_band_mask = df["band_clean"].isna()
    stats["bad_band"] = int(bad_band_mask.sum())
    df = df[~bad_band_mask].reset_index(drop=True)
    
    # è¿‡æ»¤å­—æ•°ä¸åˆç†çš„æ–‡ç« 
    df["word_count"] = df["essay"].apply(lambda x: len(str(x).split()))
    bad_len_mask = (df["word_count"] < 50) | (df["word_count"] > 1200)
    stats["bad_len"] = int(bad_len_mask.sum())
    df = df[~bad_len_mask].reset_index(drop=True)
    
    # å»é‡
    before = len(df)
    df = df.drop_duplicates(subset=["prompt", "essay"]).reset_index(drop=True)
    stats["dedup"] = before - len(df)
    
    # é‡å‘½ååˆ—
    df = df.drop(columns=["band"], errors="ignore")
    df = df.rename(columns={"band_clean": "band"})
    df = df.drop(columns=["word_count"], errors="ignore")
    
    stats["clean_rows"] = len(df)
    return df, stats


def clean_ielts_kaggle_data(df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, int]]:
    """æ¸…æ´— IELTS Kaggle æ•°æ®é›†"""
    stats = {
        "raw_rows": len(df),
        "drop_na": 0,
        "bad_band": 0,
        "bad_len": 0,
        "dedup": 0,
    }
    
    # Kaggle æ•°æ®é›†åˆ—å: Question, Essay, Overall
    # é‡å‘½åä¸ºç»Ÿä¸€æ ¼å¼
    df = df.rename(columns={
        "Question": "prompt",
        "Essay": "essay",
        "Overall": "band"
    })
    
    # åªä¿ç•™éœ€è¦çš„åˆ—
    df = df[["prompt", "essay", "band"]].copy()
    
    # åˆ é™¤ç¼ºå¤±å€¼
    df = df.dropna(subset=["prompt", "essay", "band"]).reset_index(drop=True)
    stats["drop_na"] = stats["raw_rows"] - len(df)
    
    # è§£æ band åˆ†æ•°
    df["band_clean"] = df["band"].apply(safe_parse_band)
    bad_band_mask = df["band_clean"].isna()
    stats["bad_band"] = int(bad_band_mask.sum())
    df = df[~bad_band_mask].reset_index(drop=True)
    
    # è¿‡æ»¤å­—æ•°ä¸åˆç†çš„æ–‡ç« 
    df["word_count"] = df["essay"].apply(lambda x: len(str(x).split()))
    bad_len_mask = (df["word_count"] < 50) | (df["word_count"] > 1200)
    stats["bad_len"] = int(bad_len_mask.sum())
    df = df[~bad_len_mask].reset_index(drop=True)
    
    # å»é‡
    before = len(df)
    df = df.drop_duplicates(subset=["prompt", "essay"]).reset_index(drop=True)
    stats["dedup"] = before - len(df)
    
    # é‡å‘½ååˆ—
    df = df.drop(columns=["band"], errors="ignore")
    df = df.rename(columns={"band_clean": "band"})
    df = df.drop(columns=["word_count"], errors="ignore")
    
    stats["clean_rows"] = len(df)
    return df, stats


def clean_asap_data(df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, int]]:
    """æ¸…æ´— ASAP æ•°æ®é›†"""
    stats = {
        "raw_rows": len(df),
        "drop_na": 0,
        "bad_len": 0,
        "dedup": 0,
    }
    
    # ASAP æ•°æ®é›†åˆ—å: essay_id, essay_set, essay, rater1_domain1, rater2_domain1, domain1_score
    # æˆ‘ä»¬éœ€è¦è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼: prompt, essay, band
    
    # ä¸ºæ¯ä¸ª essay_set åˆ›å»ºå¯¹åº”çš„ prompt
    essay_set_prompts = {
        1: "Write an essay about the effects of computers on people.",
        2: "Write an essay about censorship in libraries.",
        3: "Write an essay about the advantages and disadvantages of RFID technology.",
        4: "Write an essay about the role of patience in life.",
        5: "Write an essay describing a person who has influenced you.",
        6: "Write an essay about the importance of laughter.",
        7: "Write an essay about the value of persistence.",
        8: "Write an essay about the benefits of laughter in difficult times.",
    }
    
    # æ·»åŠ  prompt åˆ—
    df["prompt"] = df["essay_set"].map(essay_set_prompts)
    
    # ä½¿ç”¨ domain1_score ä½œä¸ºåˆ†æ•°
    df["band"] = df["domain1_score"]
    
    # åªä¿ç•™éœ€è¦çš„åˆ—
    df = df[["prompt", "essay", "band"]].copy()
    
    # åˆ é™¤ç¼ºå¤±å€¼
    df = df.dropna(subset=["prompt", "essay", "band"]).reset_index(drop=True)
    stats["drop_na"] = stats["raw_rows"] - len(df)
    
    # æ ‡å‡†åŒ–åˆ†æ•°åˆ° 0-9 èŒƒå›´ï¼ˆASAP åˆ†æ•°èŒƒå›´å›  essay_set è€Œå¼‚ï¼‰
    # ç®€å•å¤„ç†ï¼šå°†åˆ†æ•°å½’ä¸€åŒ–åˆ° 0-9
    min_score = df["band"].min()
    max_score = df["band"].max()
    if max_score > min_score:
        df["band"] = ((df["band"] - min_score) / (max_score - min_score)) * 9.0
        df["band"] = (df["band"].round() * 0.5).round(1)  # å››èˆäº”å…¥åˆ° 0.5
    
    # è¿‡æ»¤å­—æ•°
    df["word_count"] = df["essay"].apply(lambda x: len(str(x).split()))
    bad_len_mask = (df["word_count"] < 50) | (df["word_count"] > 1200)
    stats["bad_len"] = int(bad_len_mask.sum())
    df = df[~bad_len_mask].reset_index(drop=True)
    
    # å»é‡
    before = len(df)
    df = df.drop_duplicates(subset=["prompt", "essay"]).reset_index(drop=True)
    stats["dedup"] = before - len(df)
    df = df.drop(columns=["word_count"], errors="ignore")
    
    stats["clean_rows"] = len(df)
    return df, stats


def stratified_split(
    df: pd.DataFrame,
    seed: int = 42,
    train_per_band: int = 100,
    eval_per_band: int = 6,
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """æŒ‰ band åˆ†å±‚é‡‡æ ·ï¼Œç”Ÿæˆè®­ç»ƒé›†å’Œè¯„ä¼°é›†"""
    train_rows = []
    eval_rows = []
    
    for band, sub in df.groupby("band"):
        sub = sub.sample(frac=1, random_state=seed).reset_index(drop=True)
        
        # å…ˆå–è¯„ä¼°é›†
        n_eval = min(eval_per_band, max(1, len(sub) // 5))
        eval_part = sub.iloc[:n_eval]
        rest = sub.iloc[n_eval:]
        
        # å†å–è®­ç»ƒé›†
        n_train = min(train_per_band, len(rest))
        train_part = rest.iloc[:n_train]
        
        eval_rows.append(eval_part)
        train_rows.append(train_part)
    
    train_df = pd.concat(train_rows).sample(frac=1, random_state=seed).reset_index(drop=True)
    eval_df = pd.concat(eval_rows).sample(frac=1, random_state=seed).reset_index(drop=True)
    
    return train_df, eval_df


# ==================== ä¸»å‡½æ•° ==================== #

def main():
    print(f"ğŸš€ æ•°æ®å‡†å¤‡è„šæœ¬")
    print(f"   æ•°æ®é›†: {DATASET_NAME}\n")
    
    # 1. ä¸‹è½½åŸå§‹æ•°æ®
    raw_path = None
    if DATASET_NAME == "ielts_chillies":
        raw_path = download_ielts_chillies()
        clean_func = clean_ielts_chillies_data
        output_dir = BASE_DIR / "data" / "ielts_chillies" / "processed"
    elif DATASET_NAME == "ielts_kaggle":
        raw_path = download_ielts_kaggle()
        clean_func = clean_ielts_kaggle_data
        output_dir = BASE_DIR / "data" / "ielts_kaggle" / "processed"
    elif DATASET_NAME == "asap":
        raw_path = download_asap()
        clean_func = clean_asap_data
        output_dir = BASE_DIR / "data" / "asap" / "processed"
    else:
        print(f"âŒ æœªçŸ¥çš„æ•°æ®é›†: {DATASET_NAME}")
        print("   æ”¯æŒçš„æ•°æ®é›†: ielts_chillies, ielts_kaggle, asap")
        return
    
    if raw_path is None or not Path(raw_path).exists():
        print("âŒ æ•°æ®ä¸‹è½½å¤±è´¥")
        return
    
    # 2. åŠ è½½åŸå§‹æ•°æ®
    print(f"\nğŸ“‚ åŠ è½½åŸå§‹æ•°æ®: {raw_path}")
    if DATASET_NAME == "asap":
        df = pd.read_csv(raw_path, sep='\t', encoding='latin-1')
    else:
        df = pd.read_csv(raw_path)
    
    # 3. æ¸…æ´—æ•°æ®
    print(f"\nğŸ§¹ æ¸…æ´—æ•°æ®...")
    clean_df, stats = clean_func(df)
    
    print("\n=== æ¸…æ´—ç»Ÿè®¡ ===")
    for k, v in stats.items():
        print(f"  {k:>12}: {v}")
    
    print("\n=== Band åˆ†å¸ƒ ===")
    print(clean_df["band"].value_counts().sort_index())
    
    # 4. ä¿å­˜æ¸…æ´—åçš„å®Œæ•´æ•°æ®
    output_dir.mkdir(parents=True, exist_ok=True)
    clean_path = output_dir / "clean.csv"
    clean_df.to_csv(clean_path, index=False, encoding="utf-8-sig")
    print(f"\nğŸ’¾ ä¿å­˜å®Œæ•´æ•°æ®: {clean_path}")
    
    # 5. åˆ†å±‚é‡‡æ ·ç”Ÿæˆè®­ç»ƒé›†å’Œè¯„ä¼°é›†
    print(f"\nâœ‚ï¸  åˆ†å±‚é‡‡æ ·...")
    train_df, eval_df = stratified_split(clean_df)
    
    train_path = output_dir / "train_clean.csv"
    eval_path = output_dir / "eval_clean.csv"
    
    train_df.to_csv(train_path, index=False, encoding="utf-8-sig")
    eval_df.to_csv(eval_path, index=False, encoding="utf-8-sig")
    
    print(f"   è®­ç»ƒé›†: {train_path} ({len(train_df)} è¡Œ)")
    print(f"   è¯„ä¼°é›†: {eval_path} ({len(eval_df)} è¡Œ)")
    
    print(f"\nâœ¨ æ•°æ®å‡†å¤‡å®Œæˆï¼")
    print(f"   ç°åœ¨å¯ä»¥è¿è¡Œ: python run_evolution.py")


if __name__ == "__main__":
    main()
